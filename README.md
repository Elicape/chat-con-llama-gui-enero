# Chat con LLaMA ‚Äì v0.5

Versi√≥n funcional temprana de una interfaz gr√°fica local para ejecutar
modelos LLM mediante `llama.cpp`.

---

## ¬øQu√© es esto?

Esta aplicaci√≥n es una versi√≥n **anterior** a la primera publicaci√≥n
formal del proyecto, conservada porque ya era funcional y usable.

Permite interactuar con un modelo de lenguaje local desde una GUI simple,
sin depender de servicios online.

---

## ¬øPor qu√© existe?

En el momento en que se desarroll√≥ esta versi√≥n:

- Mi hardware no pod√≠a ejecutar aplicaciones modernas y pesadas.
- Las alternativas existentes eran complejas de configurar.
- `llama.cpp` ofrec√≠a una forma ligera y directa de ejecutar modelos locales.

Esta app nace como una soluci√≥n pr√°ctica a ese contexto.

---

## ¬øQu√© hace?

- Ejecuta un modelo local GGUF mediante `llama.cpp` (`llama-run`)
- Permite enviar mensajes desde una interfaz gr√°fica
- Muestra la respuesta del modelo en tiempo real
- Limpia secuencias de escape ANSI propias del terminal
- Mantiene la interfaz responsiva mediante hilos

---

## ¬øQu√© no hace (a prop√≥sito)?

- No gestiona m√∫ltiples modelos
- No guarda historial
- No resume contexto
- No es plug & play
- No abstrae rutas ni configuraciones

Esta simplicidad es intencional.

---

## Uso b√°sico

### Requisitos

- Python 3
- `llama.cpp` compilado localmente
- Un modelo GGUF compatible

### Preparaci√≥n

Antes de ejecutar, es necesario editar manualmente las rutas en el archivo
`gui-enero.py`:

```python
LLAMA_EXECUTABLE = "/ruta/a/llama.cpp/build/bin/llama-run"
MODEL_PATH = "/ruta/a/tu_modelo.gguf"
Estas rutas dependen del sistema y de d√≥nde se haya compilado llama.cpp.

Ejecuci√≥n
python3 gui-enero.py

Sobre esta versi√≥n

Aunque se publica como v0.5, esta aplicaci√≥n corresponde a una etapa
preliminar del proyecto.

Se conserva y publica como referencia hist√≥rica funcional, no como versi√≥n
final ni estable.

Estado del proyecto

üîí Versi√≥n cerrada
üì¶ Publicada como referencia
üõ†Ô∏è No se prev√©n mejoras sobre este c√≥digo

Agradecimientos

Proyecto llama.cpp

Autores de los modelos GGUF utilizados

Herramientas de software libre que hicieron posible la experimentaci√≥n local